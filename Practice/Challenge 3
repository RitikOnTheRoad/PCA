ğŸ“Œ Context â€“ You're the Analyst
Youâ€™ve been working as a Junior Data Scientist in a financial analytics firm. Your manager is building a predictive model using customer-derived latent scores, but the data contains heavy multicollinearity thatâ€™s confusing traditional regression.

ğŸ“© Message from Manager:

"Hey Ritik, the regression results look suspicious â€” some features are super correlated. Try dimensionality reduction first. See if PCA helps clarify the picture. Your goal is to transform this multicollinear dataset into a lower-dimensional space that can still predict the outcome accurately."

ğŸ§¾ Dataset Overview
This synthetic dataset simulates a real-world case with 200 samples and the following features:

Feature	Description
feature_1 (z1)	A latent feature (e.g., financial score)
feature_2 (2*z1)	Highly correlated with feature_1
feature_3 (z2)	Another latent feature
feature_4 (2*z2)	Highly correlated with feature_3
feature_5 (z1+z2)	Combination of both latent traits
noise_feature	Random noise
target	Dependent variable based on z1 & z2

ğŸ“ Download dataset as CSV

ğŸ¯ Your Tasks
Explore correlations and VIF to confirm multicollinearity.

Apply PCA and examine variance explained.

Run regression:

on original features (check RÂ²),

on top 2 PCs (check RÂ² again).

Interpret which PCA-transformed space better represents your data for regression.
