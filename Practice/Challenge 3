📌 Context – You're the Analyst
You’ve been working as a Junior Data Scientist in a financial analytics firm. Your manager is building a predictive model using customer-derived latent scores, but the data contains heavy multicollinearity that’s confusing traditional regression.

📩 Message from Manager:

"Hey Ritik, the regression results look suspicious — some features are super correlated. Try dimensionality reduction first. See if PCA helps clarify the picture. Your goal is to transform this multicollinear dataset into a lower-dimensional space that can still predict the outcome accurately."

🧾 Dataset Overview
This synthetic dataset simulates a real-world case with 200 samples and the following features:

Feature	Description
feature_1 (z1)	A latent feature (e.g., financial score)
feature_2 (2*z1)	Highly correlated with feature_1
feature_3 (z2)	Another latent feature
feature_4 (2*z2)	Highly correlated with feature_3
feature_5 (z1+z2)	Combination of both latent traits
noise_feature	Random noise
target	Dependent variable based on z1 & z2

📁 Download dataset as CSV

🎯 Your Tasks
Explore correlations and VIF to confirm multicollinearity.

Apply PCA and examine variance explained.

Run regression:

on original features (check R²),

on top 2 PCs (check R² again).

Interpret which PCA-transformed space better represents your data for regression.
